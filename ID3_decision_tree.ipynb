{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2           1       3                              Miss. Laina Heikkinen   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4           0       3                            Mr. William Henry Allen   \n",
       "..        ...     ...                                                ...   \n",
       "882         0       2                               Rev. Juozas Montvila   \n",
       "883         1       1                        Miss. Margaret Edith Graham   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   \n",
       "885         1       1                               Mr. Karl Howell Behr   \n",
       "886         0       3                                 Mr. Patrick Dooley   \n",
       "\n",
       "        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0      male  22.0                        1                        0   7.2500  \n",
       "1    female  38.0                        1                        0  71.2833  \n",
       "2    female  26.0                        0                        0   7.9250  \n",
       "3    female  35.0                        1                        0  53.1000  \n",
       "4      male  35.0                        0                        0   8.0500  \n",
       "..      ...   ...                      ...                      ...      ...  \n",
       "882    male  27.0                        0                        0  13.0000  \n",
       "883  female  19.0                        0                        0  30.0000  \n",
       "884  female   7.0                        1                        2  23.4500  \n",
       "885    male  26.0                        0                        0  30.0000  \n",
       "886    male  32.0                        0                        0   7.7500  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivedlist = ['Yes' if Survived == 1 else 'No' for Survived in data.iloc[:]['Survived'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclasslist = []\n",
    "for i in data.iloc[:]['Pclass'].values:\n",
    "    if i == 1:\n",
    "        pclasslist.append('First')\n",
    "    elif i == 2:\n",
    "        pclasslist.append('Second')\n",
    "    else:\n",
    "        pclasslist.append('Third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList = ['Male' if gender == 'male' else 'Female' for gender in data.iloc[:]['Sex'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "agelist = []\n",
    "for age in data.iloc[:]['Age']:\n",
    "    if age < 18:\n",
    "        agelist.append('Child')\n",
    "    elif age > 18 and age <=50:\n",
    "        agelist.append('Adult')\n",
    "    else:\n",
    "        agelist.append('Senior_citizen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Siblings/Spouses Aboard' : 'SiblingsSpousesAboard' }, inplace = True)\n",
    "sslist = ['Ssayes' if SiblingsSpousesAboard == 1 else 'Ssano' for SiblingsSpousesAboard in data.iloc[:]['SiblingsSpousesAboard'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Parents/Children Aboard' : 'ParentsChildrenAboard' }, inplace = True)\n",
    "plist = ['Pcano' if ParentsChildrenAboard == 0 else 'Pcayes' for ParentsChildrenAboard in data.iloc[:]['ParentsChildrenAboard'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "farelist = []\n",
    "for fare in data.iloc[:]['Fare'].values:\n",
    "    if fare <= 50:\n",
    "        farelist.append('Low')\n",
    "    elif fare > 50 and fare <= 200:\n",
    "        farelist.append('Moderate')\n",
    "    else:\n",
    "        farelist.append('High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['pclass'] = pclasslist\n",
    "processed_data['gender'] = genderList\n",
    "processed_data['age'] = agelist\n",
    "processed_data['ssa'] = sslist\n",
    "processed_data['pca'] = plist\n",
    "processed_data['fare'] = farelist\n",
    "processed_data['survived'] = survivedlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ssa</th>\n",
       "      <th>pca</th>\n",
       "      <th>fare</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Third</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssayes</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssayes</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Third</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssayes</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Third</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Second</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>First</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Third</td>\n",
       "      <td>Female</td>\n",
       "      <td>Child</td>\n",
       "      <td>Ssayes</td>\n",
       "      <td>Pcayes</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>First</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Third</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Ssano</td>\n",
       "      <td>Pcano</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  gender    age     ssa     pca      fare survived\n",
       "0     Third    Male  Adult  Ssayes   Pcano       Low       No\n",
       "1     First  Female  Adult  Ssayes   Pcano  Moderate      Yes\n",
       "2     Third  Female  Adult   Ssano   Pcano       Low      Yes\n",
       "3     First  Female  Adult  Ssayes   Pcano  Moderate      Yes\n",
       "4     Third    Male  Adult   Ssano   Pcano       Low       No\n",
       "..      ...     ...    ...     ...     ...       ...      ...\n",
       "882  Second    Male  Adult   Ssano   Pcano       Low       No\n",
       "883   First  Female  Adult   Ssano   Pcano       Low      Yes\n",
       "884   Third  Female  Child  Ssayes  Pcayes       Low       No\n",
       "885   First    Male  Adult   Ssano   Pcano       Low      Yes\n",
       "886   Third    Male  Adult   Ssano   Pcano       Low       No\n",
       "\n",
       "[887 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv('new_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    lines = csv.reader(open(filename,'r'))\n",
    "    dataset = list(lines)\n",
    "    headers = dataset.pop(0)\n",
    "    return dataset, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = []\n",
    "        self.answer = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, features):\n",
    "    last_col = [row[-1] for row in data]\n",
    "    if len(set(last_col)) == 1:\n",
    "        node = Node('')\n",
    "        node.answer = last_col[0]\n",
    "        return node\n",
    "    n = len(data[0]) - 1\n",
    "    gains = [0]*n\n",
    "    for col in range(n):\n",
    "        gains[col] = compute_gain(data, col)\n",
    "    split = gains.index(max(gains))\n",
    "    node = Node(features[split])\n",
    "    fea = features[:split] + features[split+1:]\n",
    "    attr, dic = subtables(data, split, delete=True)\n",
    "    for x in range(len(attr)):\n",
    "        child = build_tree(dic[attr[x]], fea)\n",
    "        node.children.append((attr[x], child))\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gain(data, col):\n",
    "    att_values, dic = subtables(data, col, delete=False)\n",
    "    total_entropy = entropy([row[-1] for row in data])\n",
    "    for x in range(len(att_values)):\n",
    "        ratio = len(dic[att_values[x]]) / (len(data) * 1.0)\n",
    "        entro = entropy([row[-1] for row in dic[att_values[x]]])\n",
    "        total_entropy -= ratio*entro\n",
    "    return total_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtables(data, col, delete):\n",
    "    dic = {}\n",
    "    coldata = [row[col] for row in data]\n",
    "    attr = list(set(coldata))\n",
    "    counts = [0]*len(attr)\n",
    "    r = len(data)\n",
    "    c = len(data)\n",
    "    for x in range(len(attr)):\n",
    "        for y in range(r):\n",
    "            if data[y][col] == attr[x]:\n",
    "                counts[x] += 1\n",
    "    for x in range(len(attr)):\n",
    "        dic[attr[x]] = [[0 for i in range(c)] for j in range(counts[x])]\n",
    "        pos = 0\n",
    "        for y in range(r):\n",
    "            if data[y][col] == attr[x]:\n",
    "                if delete:\n",
    "                    del data[y][col]\n",
    "                dic[attr[x]][pos] = data[y]\n",
    "                pos += 1\n",
    "    return attr, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(S):\n",
    "    attr = list(set(S))\n",
    "    if len(attr) == 1:\n",
    "        return 0\n",
    "    counts = [0,0]\n",
    "    for i in range(2):\n",
    "        counts[i] = sum([1 for x in S if attr[i] == x]) / (len(S) * 1.0)\n",
    "    sums = 0\n",
    "    for cnt in counts:\n",
    "        sums += -1 * cnt * math.log(cnt, 2)\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, level):\n",
    "    if node.answer != '':\n",
    "        print(\" \"*level, node.answer)\n",
    "        return\n",
    "    print(\" \"*level, node.attribute)\n",
    "    for value, n in node.children:\n",
    "        print(\" \"*(level+1), value)\n",
    "        print_tree(n, level+2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree is\n",
      " sex\n",
      "  Male\n",
      "   pclass\n",
      "    Third\n",
      "     No\n",
      "    Second\n",
      "     Yes\n",
      "    First\n",
      "     No\n",
      "  Female\n",
      "   pclass\n",
      "    Third\n",
      "     pca\n",
      "      Pcayes\n",
      "       Yes\n",
      "      Pcano\n",
      "       age\n",
      "        Child\n",
      "         No\n",
      "        Adult\n",
      "         ssa\n",
      "          Ssano\n",
      "           Yes\n",
      "          Ssayes\n",
      "           No\n",
      "    Second\n",
      "     Yes\n",
      "    First\n",
      "     Yes\n"
     ]
    }
   ],
   "source": [
    "dataset, features = load_csv('new_titanic.csv')\n",
    "# print(dataset[:10], features)\n",
    "node = build_tree(dataset[:20], features)\n",
    "print('The decision tree is')\n",
    "print_tree(node, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Representation of tree on training set\n",
      "  \n",
      "{'index': 1, 'value': 'Male', 'left': {'index': 0, 'value': 'Third', 'left': {'index': 5, 'value': 'Moderate', 'left': 'Yes', 'right': 'Yes'}, 'right': {'index': 5, 'value': 'Moderate', 'left': 'Yes', 'right': 'No'}}, 'right': {'index': 0, 'value': 'Second', 'left': {'index': 2, 'value': 'Senior_citizen', 'left': 'No', 'right': 'No'}, 'right': {'index': 4, 'value': 'Pcayes', 'left': 'No', 'right': 'No'}}}\n",
      "  \n",
      "Attributes \n",
      "['pclass', 'sex', 'age', 'ssa', 'pca', 'fare', 'survived']\n",
      "Textual Representation of JSON tree\n",
      "[ATTRIBUTE[2] = Male]\n",
      "\t[ATTRIBUTE[1] = Third]\n",
      "\t\t[ATTRIBUTE[6] = Moderate]\n",
      "   [Yes]\n",
      "   [Yes]\n",
      "\t\t[ATTRIBUTE[6] = Moderate]\n",
      "   [Yes]\n",
      "   [No]\n",
      "\t[ATTRIBUTE[1] = Second]\n",
      "\t\t[ATTRIBUTE[3] = Senior_citizen]\n",
      "   [No]\n",
      "   [No]\n",
      "\t\t[ATTRIBUTE[5] = Pcayes]\n",
      "   [No]\n",
      "   [No]\n",
      "  \n",
      "Implementing Single Split\n",
      "Scores: [82.48587570621469]\n",
      "Accuracy: 82.486%\n",
      "  \n",
      "Implementing k-cross validation\n",
      "Scores: [79.09604519774011, 80.22598870056498, 80.7909604519774, 76.27118644067797, 81.35593220338984]\n",
      "Mean Accuracy: 79.548%\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "from csv import reader\n",
    "import math\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    return dataset\n",
    "\n",
    "# Split a dataset into a train and test set\n",
    "def train_test_split(dataset, split=0.80):\n",
    "    train = list()\n",
    "    train_size = split * len(dataset)\n",
    "    dataset_copy = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = randrange(len(dataset_copy))\n",
    "        train.append(dataset_copy.pop(index))\n",
    "    return train, dataset_copy\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a single split\n",
    "def evaluate_algorithm_single(dataset, algorithm, *args):\n",
    "    train_set,test_set=train_test_split(dataset,0.80)\n",
    "    scores = list()\n",
    "    predicted = algorithm(train_set, test_set, *args)\n",
    "    actual = [row[-1] for row in test_set]\n",
    "    accuracy = accuracy_metric(actual, predicted)\n",
    "    scores.append(accuracy)\n",
    "    return scores\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    " \n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "# Calculate the Entropy for a split dataset\n",
    "def entropy(groups, classes,b_score):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    ent = 0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            if p > 0 :\n",
    "                score=(p*math.log(p,2))\n",
    "        # weight the group score by its relative size i.e Entrpy gain\n",
    "        ent-=(score*(size/n_instances))\n",
    "    return ent\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset,split_parameter):\n",
    "    if split_parameter=='entropy':# this is invoked for parameter entropy\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 1, None\n",
    "        for index in range(len(dataset[0])-1):\n",
    "            for row in dataset:\n",
    "                groups = test_split(index, row[index], dataset)\n",
    "                ent = entropy(groups, class_values,b_score)\n",
    "                if ent < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], ent, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "    elif split_parameter=='gini':# this is invoked for parameter gini\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 99999, 99999, 1, None\n",
    "        for index in range(len(dataset[0])-1):\n",
    "            for row in dataset:\n",
    "                groups = test_split(index, row[index], dataset)\n",
    "                gini = gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left,split_parameter)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right,split_parameter)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "\n",
    "def build_tree(train, max_depth, min_size,split_parameter):\n",
    "    root = get_split(train,split_parameter)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[ATTRIBUTE[%s] = %.50s]' % ((depth*'\\t', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "\n",
    "def decision_tree(train, test, max_depth, min_size,split_parameter):\n",
    "    tree = build_tree(train, max_depth, min_size,split_parameter)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "\n",
    "# Datasets used tic_tac_toe,iris\n",
    "# load and prepare data\n",
    "filename = 'new_titanic.csv'#Provide the CSV filename on which you want to test\n",
    "dataset = load_csv(filename)\n",
    "# Tree model creation on training set\n",
    "n_folds = 5\n",
    "max_depth = 3\n",
    "min_size = 1\n",
    "split_parameter='entropy'  # 'entrpy'/'gini'\n",
    "train_set,test_set=train_test_split(dataset,0.80)\n",
    "tree= build_tree(train_set, max_depth, min_size,split_parameter)\n",
    "print('Dictionary Representation of tree on training set')\n",
    "print('  ')\n",
    "print(tree)\n",
    "print('  ')\n",
    "print('Attributes ')\n",
    "print(dataset[0])\n",
    "print('Textual Representation of JSON tree')\n",
    "print_tree(tree)\n",
    "scores_1 = evaluate_algorithm_single(dataset,decision_tree,max_depth,min_size,split_parameter)\n",
    "print('  ')\n",
    "print('Implementing Single Split')\n",
    "print('Scores: %s' % scores_1)\n",
    "print('Accuracy: %.3f%%' % (sum(scores_1)/float(len(scores_1))))\n",
    "#Calculating scores for k cross validation by setting n_folds value\n",
    "print('  ')\n",
    "print('Implementing k-cross validation')\n",
    "scores_2 = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size,split_parameter)\n",
    "print('Scores: %s' % scores_2)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores_2)/float(len(scores_2))))\n",
    "\n",
    "#actual = [row[-1] for row in test_set]\n",
    "#print(actual)\n",
    "#predicted = decision_tree(train_set,test_set,max_depth, min_size)\n",
    "#print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pos_and_neg(data):\n",
    "#     positive,negative = 0,0\n",
    "#     for d in data.iloc[:]['survived']:\n",
    "#         if d == 'Yes':\n",
    "#             positive += 1\n",
    "#         else:\n",
    "#             negative += 1\n",
    "#     return positive, negative\n",
    "\n",
    "\n",
    "# def cal_entropy(data):\n",
    "#     positive, negative = pos_and_neg(data)\n",
    "#     t1 = positive/(positive + negative)\n",
    "#     t2 = negative/(positive + negative)\n",
    "#     entropy = -(t1)*(math.log2(t1)) - (t2)*(math.log2(t2))\n",
    "#     return entropy\n",
    "\n",
    "# # cal_entropy(processed_data)\n",
    "\n",
    "\n",
    "# columns = list(processed_data.columns)\n",
    "# def func(data):\n",
    "#     for col in columns:\n",
    "#         for d in data.iloc[:][col]:\n",
    "            \n",
    "#             pass\n",
    "# # func(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pclass     sex    age     ssa     pca survived\n",
      "0     third    male  adult  ssayes   pcano       no\n",
      "1     first  female  adult  ssayes   pcano      yes\n",
      "2     third  female  adult   ssano   pcano      yes\n",
      "3     first  female  adult  ssayes   pcano      yes\n",
      "4     third    male  adult   ssano   pcano       no\n",
      "..      ...     ...    ...     ...     ...      ...\n",
      "882  second    male  adult   ssano   pcano       no\n",
      "883   first  female  adult   ssano   pcano      yes\n",
      "884   third  female  child  ssayes  pcayes       no\n",
      "885   first    male  adult   ssano   pcano      yes\n",
      "886   third    male  adult   ssano   pcano       no\n",
      "\n",
      "[887 rows x 6 columns]\n",
      "\n",
      " Total Entropy of titanic Data Set: 0.9618806789594468\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "df = pd.read_csv('processed_titanic.csv')\n",
    "df.drop(['fare'],axis=1,inplace=True)\n",
    "print(df)\n",
    "\n",
    "def entropy(probs):  \n",
    "    import math\n",
    "    return sum( [-prob*math.log(prob, 2) for prob in probs] )\n",
    "\n",
    "def entropy_of_list(a_list):\n",
    "    cnt = Counter(x for x in a_list)\n",
    "    num_instances = len(a_list)*1.0\n",
    "    probs = [x / num_instances for x in cnt.values()]\n",
    "    return entropy(probs)\n",
    "\n",
    "total_entropy = entropy_of_list(df['survived'])\n",
    "\n",
    "print(\"\\n Total Entropy of titanic Data Set:\",total_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(df, split_attribute_name, target_attribute_name, trace=0):\n",
    "    df_split = df.groupby(split_attribute_name)\n",
    "    nobs = len(df.index) * 1.0\n",
    "    df_agg_ent = df_split.agg({target_attribute_name : [entropy_of_list, lambda x: len(x)/nobs] })[target_attribute_name]\n",
    "    df_agg_ent.columns = ['Entropy', 'po']\n",
    "    \n",
    "    new_entropy = sum( df_agg_ent['Entropy'] * df_agg_ent['po'] )\n",
    "    old_entropy = entropy_of_list(df[target_attribute_name])\n",
    "    return old_entropy - new_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def id3(df, target_attribute_name, attribute_names, default_class=None):\n",
    "    cnt = Counter(x for x in df[target_attribute_name])# class of YES /NO\n",
    "    if len(cnt) == 1:\n",
    "        return next(iter(cnt))\n",
    "    elif df.empty or (not attribute_names):\n",
    "        return default_class \n",
    "    else:\n",
    "        default_class = max(cnt.keys()) \n",
    "        gainz = [information_gain(df, attr, target_attribute_name) for attr in attribute_names] #\n",
    "        index_of_max = gainz.index(max(gainz))\n",
    "        best_attr = attribute_names[index_of_max]\n",
    "        tree = {best_attr:{}} # Iniiate the tree with best attribute as a node \n",
    "        remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
    "\n",
    "        \n",
    "        for attr_val, data_subset in df.groupby(best_attr):\n",
    "            subtree = id3(data_subset,target_attribute_name,remaining_attribute_names,default_class)\n",
    "            tree[best_attr][attr_val] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Attributes: ['pclass', 'sex', 'age', 'ssa', 'pca', 'survived']\n",
      "Predicting Attributes: ['pclass', 'sex', 'age', 'ssa', 'pca']\n"
     ]
    }
   ],
   "source": [
    "attribute_names = list(df.columns)\n",
    "print(\"List of Attributes:\", attribute_names) \n",
    "attribute_names.remove('survived') #Remove the class attribute \n",
    "print(\"Predicting Attributes:\", attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Resultant Decision Tree is :\n",
      "\n",
      "{'sex': {'female': {'pclass': {'first': 'yes',\n",
      "                               'second': {'age': {'adult': {'ssa': {'ssano': 'yes',\n",
      "                                                                    'ssayes': 'no'}},\n",
      "                                                  'child': 'yes'}},\n",
      "                               'third': {'age': {'adult': {'ssa': {'ssano': 'yes',\n",
      "                                                                   'ssayes': {'pca': {'pcano': 'no',\n",
      "                                                                                      'pcayes': 'yes'}}}},\n",
      "                                                 'child': {'ssa': {'ssano': {'pca': {'pcano': 'yes',\n",
      "                                                                                     'pcayes': 'no'}},\n",
      "                                                                   'ssayes': {'pca': {'pcano': 'yes',\n",
      "                                                                                      'pcayes': 'yes'}}}}}}}},\n",
      "         'male': {'pclass': {'first': {'ssa': {'ssano': {'pca': {'pcano': {'age': {'adult': 'yes'}},\n",
      "                                                                 'pcayes': 'no'}},\n",
      "                                               'ssayes': 'no'}},\n",
      "                             'second': {'age': {'adult': {'ssa': {'ssano': {'pca': {'pcano': 'yes'}}}}}},\n",
      "                             'third': {'age': {'adult': 'no',\n",
      "                                               'child': {'pca': {'pcano': {'ssa': {'ssano': 'yes'}},\n",
      "                                                                 'pcayes': 'no'}}}}}}}}\n",
      "Best Attribute :\n",
      " sex\n",
      "Tree Keys:\n",
      " dict_keys(['female', 'male'])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "tree = id3(df[:50],'survived',attribute_names)\n",
    "print(\"\\n\\nThe Resultant Decision Tree is :\\n\")\n",
    "pprint(tree)\n",
    "attribute = next(iter(tree))\n",
    "print(\"Best Attribute :\\n\",attribute)\n",
    "print(\"Tree Keys:\\n\",tree[attribute].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(instance, tree, default=None): \n",
    "    attribute = next(iter(tree))\n",
    "    if instance[attribute] in tree[attribute].keys(): # Value of the attributs in  set of Tree keys  \n",
    "        result = tree[attribute][instance[attribute]]\n",
    "        if isinstance(result, dict):\n",
    "            return classify(instance, result)\n",
    "        else:\n",
    "            return result # this is a label\n",
    "    else:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.6335963923337091\n"
     ]
    }
   ],
   "source": [
    "df['predicted'] = df.apply(classify, axis=1, args=(tree,'No') )\n",
    "\n",
    "print('Accuracy is: ' + str(sum(df['survived']==df['predicted']) / (1.0*len(df.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
